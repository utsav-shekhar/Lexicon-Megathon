{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.14","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"none","dataSources":[],"dockerImageVersionId":30786,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":false}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"import torch\nimport torch.nn as nn\nimport torch.optim as optim\nfrom nltk.sentiment.vader import SentimentIntensityAnalyzer\nfrom sklearn.preprocessing import StandardScaler\nimport numpy as np\nimport nltk\n\n# Download the VADER lexicon if not already downloaded\nnltk.download('vader_lexicon')\n\n# Initialize VADER Sentiment Intensity Analyzer\nsia = SentimentIntensityAnalyzer()\n\n# Sample data\nconcerns = [\n    \"I'm feeling really anxious and can't sleep.\",\n    \"I am just a bit stressed.\",\n    \"I am extremely depressed and overwhelmed with everything.\"\n]\n\n# Feature extraction function\ndef extract_features(text):\n    # VADER sentiment score (compound value)\n    sentiment_score = sia.polarity_scores(text)[\"compound\"]\n    \n    # Basic keyword analysis (count of emotional keywords)\n    keywords = [\"anxiety\", \"depression\", \"stress\", \"overwhelmed\", \"panic\"]\n    keyword_count = sum(1 for word in keywords if word in text.lower())\n    \n    # Polarity Shift (additional placeholder, assuming tracking over time)\n    # Here, assuming a static polarity shift of 0.1 for demonstration purposes\n    polarity_shift = 0.1  # Adjust based on previous user inputs in a real scenario\n    \n    # Return as numpy array\n    return np.array([sentiment_score, keyword_count, polarity_shift])\n\n# Create feature and target arrays\nX = np.array([extract_features(text) for text in concerns])\ny = np.array([8, 4, 9])  # Sample intensity scores (1-10), ideally provided as labeled data\n\n# Scale features for neural network input\nscaler = StandardScaler()\nX = scaler.fit_transform(X)\nX = torch.FloatTensor(X)\ny = torch.FloatTensor(y)\n\n# Define a simple neural network model\nclass IntensityScoreModel(nn.Module):\n    def _init_(self):\n        super(IntensityScoreModel, self)._init_()\n        self.fc1 = nn.Linear(3, 10)  # Input layer with 3 features\n        self.fc2 = nn.Linear(10, 1)  # Output layer with a single intensity score\n    \n    def forward(self, x):\n        x = torch.relu(self.fc1(x))\n        x = self.fc2(x)\n        return x\n\n# Initialize model, loss function, and optimizer\nmodel = IntensityScoreModel()\ncriterion = nn.MSELoss()  # Mean Squared Error for regression\noptimizer = optim.Adam(model.parameters(), lr=0.01)\n\n# Training loop\nnum_epochs = 100\nfor epoch in range(num_epochs):\n    model.train()\n    \n    # Forward pass\n    outputs = model(X).squeeze()\n    loss = criterion(outputs, y)\n    \n    # Backward pass and optimization\n    optimizer.zero_grad()\n    loss.backward()\n    optimizer.step()\n    \n    if (epoch+1) % 10 == 0:\n        print(f'Epoch [{epoch+1}/{num_epochs}], Loss: {loss.item():.4f}')\n\n# Testing model prediction on new concerns\nnew_concern = \"I feel mildly anxious but managing it.\"\nnew_features = extract_features(new_concern)\nnew_features = scaler.transform(new_features.reshape(1, -1))\nnew_features = torch.FloatTensor(new_features)\npredicted_intensity = model(new_features).item()\n\nprint(f'Predicted Intensity Score for new concern: {predicted_intensity:.2f}')","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"execution_count":null,"outputs":[]}]}